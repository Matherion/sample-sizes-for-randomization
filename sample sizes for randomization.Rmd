---
title: "Randomization Results Section"
author: "Gjalt-Jorn Ygram Peters & Stefan Gruijters"
date: "`r format(Sys.time(), '%d %b %Y at %H:%M:%S');`"
output: html_document
---

```{r preparation, echo=FALSE, results="hide", message=FALSE, error=FALSE, cache=FALSE}

################################################################################
################################################################################
### Configure basic settings
################################################################################
################################################################################

########################################################################
### Paths
########################################################################

### Add any relevant paths to this vector. The script will select the
### correct path itself.

basePathVector <- c("B:/Data/research/randomization/sample-sizes-for-randomization",
                    "");

########################################################################
### Set the variables with the paths
########################################################################

### Check which paths exist and set the first existing path in the list
### as the base path
basePath <- basePathVector[sapply(basePathVector, dir.exists)][1];

### Set the additional paths
workingPath <- basePath;
outputPath <- basePath;

########################################################################
### Packages
########################################################################

### For function 'vecTxt' and 'safeRequire'; also loads ggplot2 which
### we'll use for the plots
require('userfriendlyscience', quietly = TRUE);

### For function 'mvrnorm'
require('MASS', quietly = TRUE);

### For functions 'raply' and 'ddply'
require('plyr', quietly = TRUE);

### For functions 'melt' and 'dcast'
require('reshape2', quietly = TRUE)

### For function 'pander'
require('pander', quietly = TRUE)

### For knitting and accessing knitr functions
require('knitr', quietly = TRUE);

########################################################################
### Settings
########################################################################

### Setting default knitting options
knitr::opts_chunk$set(echo=FALSE);
knitr::opts_chunk$set(comment=NA);
knitr::opts_chunk$set(dev="png", 
		  		            dev.args=list(type="cairo"),
			    	          dpi=100);
knitr::opts_chunk$set(fig.width=5);
knitr::opts_chunk$set(fig.height=5);
knitr::opts_chunk$set(cache=TRUE);
knitr::opts_knit$set(eval.after = 'fig.cap');

options(scipen=100);
options(figure_counter = TRUE);
options(table_counter = TRUE);

setFigCapNumbering(figure_counter_str = "Figure %s: ",
                   figureClass = "caption",
                   figureInlineStyle = NULL);
setTabCapNumbering(table_counter_str = ":Table %s: ");

```

The results for the simulation with one nuisance variable are shown in Figure 1 and Table 1. As sample sizes increase and effect sizes decrease, the probability of the nuisance variable differing between groups with a given effect size decreases. Even with only 20 participants (10 in each cell), the probability of one group mean being one standard deviation higher than the other group mean is only 4%. However, in one in three studies with a total sample size of 20, one group's mean is half a standard deviation higher than the other group's mean (a 'moderately large' difference). If smaller differences between groups are already considered problematic, the sample size required to constrain the probability of non-equivalent groups rapidly increases.

If a difference between groups of Cohen's d = .2 or larger is considered problematic, even with a total sample size of 150 participants (75 per cell) still about one fifth of the studies (20%) will in fact be quasi-experiments with respect to this nuisance variable. To get the proportion of studies with non-equivalent groups below 10%, at least XXXXXXXXXX participants are required.

```{r fig.cap="Probability of one nuisance variable differing between groups for Cohen's d's from .2, .3, .4 and .5 for sample sizes from 20-500."}

  df <- data.frame(x = seq(10, 500, 1),
                   d.2 = pdExtreme(.2, seq(10, 500, 1)),
                   d.3 = pdExtreme(.3, seq(10, 500, 1)),
                   d.4 = pdExtreme(.4, seq(10, 500, 1)),
                   d.5 = pdExtreme(.5, seq(10, 500, 1)));

  ggplot(df, aes(x=x)) +
    geom_ribbon(aes(ymax = 1, ymin=d.2), fill="#008800", alpha=.33) +
    geom_ribbon(aes(ymax = d.2, ymin=d.3), fill="#FFAA00", alpha=.33) +
    geom_ribbon(aes(ymax = d.3, ymin=d.4), fill="#FF9900", alpha=.33) +
    geom_ribbon(aes(ymax = d.4, ymin=d.5), fill="#FF6600", alpha=.33) +
    geom_ribbon(aes(ymax = d.5, ymin=0), fill="#FF3300", alpha=.33) +
    geom_line(aes(y=d.2), color="#FFAA00", size=1) +
    geom_line(aes(y=d.3), color="#FF9900", size=1) +
    geom_line(aes(y=d.4), color="#FF6600", size=1) +
    geom_line(aes(y=d.5), color="#FF3300", size=1) +
    geom_hline(yintercept = .05) +
    geom_vline(xintercept = min(df[df$d.2 <= .05, 'x'])) +
    geom_vline(xintercept = min(df[df$d.3 <= .05, 'x'])) +
    geom_vline(xintercept = min(df[df$d.4 <= .05, 'x'])) +
    geom_vline(xintercept = min(df[df$d.5 <= .05, 'x'])) +
    xlab("Total sample size") +
    ylab("Probability of nonequivalent groups") +
    ggtitle("One potential confounder") +
    coord_cartesian(ylim=c(0,1)) +
    scale_x_continuous(breaks=seq(0, 500, by=100),
                       sec.axis=dup_axis(breaks=c(min(df[df$d.2 <= .05, 'x']),
                                         min(df[df$d.3 <= .05, 'x']),
                                         min(df[df$d.4 <= .05, 'x']),
                                         min(df[df$d.5 <= .05, 'x'])))) +
    theme_bw();

```

Of course, in most situations, assuming that only one nuisance variable exists is almost as naive as assuming that non nuisance variables exist. Therefore, we also computed these probabilities as a function of the number of nuisance variables. For a Cohen's d of .5, these probabilities are shown in Figure 2 and Table 2, and for a Cohen's d of .2, in Figure 3 and Table 3.

```{r fig.cap="Probability of ten nuisance variables differing between groups for Cohen's d's from .2, .3, .4 and .5 for sample sizes from 20-1000."}

  df <- data.frame(x = seq(10, 1000, 1),
                   d.2 = 1 - pdMild(.2, seq(10, 1000, 1))^10,
                   d.3 = 1 - pdMild(.3, seq(10, 1000, 1))^10,
                   d.4 = 1 - pdMild(.4, seq(10, 1000, 1))^10,
                   d.5 = 1 - pdMild(.5, seq(10, 1000, 1))^10);

  ggplot(df, aes(x=x)) +
    geom_ribbon(aes(ymax = 1, ymin=d.2), fill="#008800", alpha=.33) +
    geom_ribbon(aes(ymax = d.2, ymin=d.3), fill="#FFAA00", alpha=.33) +
    geom_ribbon(aes(ymax = d.3, ymin=d.4), fill="#FF9900", alpha=.33) +
    geom_ribbon(aes(ymax = d.4, ymin=d.5), fill="#FF6600", alpha=.33) +
    geom_ribbon(aes(ymax = d.5, ymin=0), fill="#FF3300", alpha=.33) +
    geom_line(aes(y=d.2), color="#FFAA00", size=1) +
    geom_line(aes(y=d.3), color="#FF9900", size=1) +
    geom_line(aes(y=d.4), color="#FF6600", size=1) +
    geom_line(aes(y=d.5), color="#FF3300", size=1) +
    geom_hline(yintercept = .05) +
    geom_vline(xintercept = min(df[df$d.2 <= .05, 'x'])) +
    geom_vline(xintercept = min(df[df$d.3 <= .05, 'x'])) +
    geom_vline(xintercept = min(df[df$d.4 <= .05, 'x'])) +
    geom_vline(xintercept = min(df[df$d.5 <= .05, 'x'])) +
    xlab("Total sample size") +
    ylab("Probability of nonequivalent groups") +
    ggtitle("Ten potential confounders") +
    coord_cartesian(ylim=c(0,1)) +
    scale_x_continuous(breaks=seq(0, 1000, by=100),
                       sec.axis=dup_axis(breaks=c(min(df[df$d.2 <= .05, 'x']),
                                         min(df[df$d.3 <= .05, 'x']),
                                         min(df[df$d.4 <= .05, 'x']),
                                         min(df[df$d.5 <= .05, 'x'])))) +
    theme_bw();

```


```{r fig.cap="Probability of one hundred nuisance variables differing between groups for Cohen's d's from .2, .3, .4 and .5 for sample sizes from 20-1000."}

  df <- data.frame(x = seq(10, 1000, 1),
                   d.2 = 1 - pdMild(.2, seq(10, 1000, 1))^100,
                   d.3 = 1 - pdMild(.3, seq(10, 1000, 1))^100,
                   d.4 = 1 - pdMild(.4, seq(10, 1000, 1))^100,
                   d.5 = 1 - pdMild(.5, seq(10, 1000, 1))^100);

  ggplot(df, aes(x=x)) +
    geom_ribbon(aes(ymax = 1, ymin=d.2), fill="#008800", alpha=.33) +
    geom_ribbon(aes(ymax = d.2, ymin=d.3), fill="#FFAA00", alpha=.33) +
    geom_ribbon(aes(ymax = d.3, ymin=d.4), fill="#FF9900", alpha=.33) +
    geom_ribbon(aes(ymax = d.4, ymin=d.5), fill="#FF6600", alpha=.33) +
    geom_ribbon(aes(ymax = d.5, ymin=0), fill="#FF3300", alpha=.33) +
    geom_line(aes(y=d.2), color="#FFAA00", size=1) +
    geom_line(aes(y=d.3), color="#FF9900", size=1) +
    geom_line(aes(y=d.4), color="#FF6600", size=1) +
    geom_line(aes(y=d.5), color="#FF3300", size=1) +
    geom_hline(yintercept = .05) +
    geom_vline(xintercept = min(df[df$d.2 <= .05, 'x'])) +
    geom_vline(xintercept = min(df[df$d.3 <= .05, 'x'])) +
    geom_vline(xintercept = min(df[df$d.4 <= .05, 'x'])) +
    geom_vline(xintercept = min(df[df$d.5 <= .05, 'x'])) +
    xlab("Total sample size") +
    ylab("Probability of nonequivalent groups") +
    ggtitle("Ten potential confounders") +
    coord_cartesian(ylim=c(0,1)) +
    scale_x_continuous(breaks=seq(0, 1000, by=100),
                       sec.axis=dup_axis(breaks=c(min(df[df$d.2 <= .05, 'x']),
                                         min(df[df$d.3 <= .05, 'x']),
                                         min(df[df$d.4 <= .05, 'x']),
                                         min(df[df$d.5 <= .05, 'x'])))) +
    theme_bw();

```
